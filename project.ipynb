{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> BİTİRME PROJESİ A </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from typing import List\n",
    "import string\n",
    "from jpype import JClass, getDefaultJVMPath, startJVM\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim \n",
    "from gensim import corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"assets/comments/comment.csv\")\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Türkçe Gereksiz Kelimeler\n",
    "with open('assets/turkish-stop-words.txt', 'r', encoding='utf-8') as file:\n",
    "    stopWords = file.read()\n",
    "    print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zembere JVM Başlatma\n",
    "ZEMBEREK_PATH = r'zemberek/zemberek-full.jar' \n",
    "startJVM(getDefaultJVMPath(), '-ea', '-Djava.class.path=%s' % (ZEMBEREK_PATH))\n",
    "\n",
    "TurkishMorphology = JClass('zemberek.morphology.TurkishMorphology')\n",
    "morphology = TurkishMorphology.createWithDefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metin Ön İşleme\n",
    "inputFilePath = 'assets/comments/comment.csv'\n",
    "outputFilePath = 'assets/processed_comments/processed_comment.txt'\n",
    "\n",
    "with open(outputFilePath, 'w', encoding='utf-8') as file:\n",
    "    file.write('')\n",
    "\n",
    "with open(inputFilePath, 'r', encoding='utf-8') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    headers = next(csv_reader)\n",
    "    try:\n",
    "        text_column_index = headers.index('text')\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"text sütunu bulunamadı.\")\n",
    "\n",
    "    lines = [line[text_column_index] for line in csv_reader]\n",
    "\n",
    "for line in lines:\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    wordsWithoutPunctuation = line.translate(translator)\n",
    "\n",
    "    analysisWords = morphology.analyzeAndDisambiguate(wordsWithoutPunctuation).bestAnalysis()\n",
    "\n",
    "    \n",
    "\n",
    "    pos: List[str] = []\n",
    "    for i, analysis in enumerate(analysisWords, start=1):\n",
    "        print(f'Analiz {i}: {analysis}')\n",
    "\n",
    "\n",
    "        pos.append(str(analysis.getLemmas()[0]))\n",
    "\n",
    "    withoutUnk = [word for word in pos if word != 'UNK']\n",
    "    withoutStopWords = [word for word in withoutUnk if word.lower() not in stopWords]\n",
    "    withoutNumericals = [word for word in withoutStopWords if not word.isdigit()]\n",
    "\n",
    "    result_content = \" \".join(withoutNumericals)\n",
    "\n",
    "    with open(outputFilePath, 'a', encoding='utf-8') as file:\n",
    "        file.write(result_content + '\\n')\n",
    "\n",
    "print(f'Analiz edilen kelimeler (UNK olmayanlar) dosyaya yazıldı: {outputFilePath}')\n",
    "\n",
    "txtFilePath = 'assets/processed_comments/processed_comment.txt'\n",
    "csvFilePath = 'assets/processed_comments/processed_comment.csv'\n",
    "with open(txtFilePath, 'r', encoding='utf-8') as txtfile, open(csvFilePath, 'w', newline='', encoding='utf-8') as csvfile:        \n",
    "    lines = txtfile.readlines()\n",
    "    \n",
    "    csvWriter = csv.writer(csvfile)\n",
    "    csvWriter.writerow(['text'])\n",
    "\n",
    "    for i, line in enumerate(lines, start=1):\n",
    "        csvWriter.writerow([line.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ön İşlemden Sonra Yorumlar\n",
    "processed_df = pd.read_csv('assets/processed_comments/processed_comment.csv')\n",
    "processed_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kelime Bulutu Haritası\n",
    "df = pd.read_csv('assets/processed_comments/processed_comment.csv')\n",
    "text_data = ' '.join(df['text'].dropna())\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text_data)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>LDA MODELİ</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicCountRange = range(8,30,2)\n",
    "\n",
    "coherenceCountList = list()\n",
    "topicCountList = list()\n",
    "\n",
    "#LDA Model Parametreleri\n",
    "df = pd.read_csv('assets/processed_comments/processed_comment.csv')\n",
    "tokenized = [comment.split() for comment in df[\"text\"].astype(str)]\n",
    "dictionary = corpora.Dictionary(tokenized)\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.7)\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in tokenized]\n",
    "\n",
    "for topicCount in topicCountRange:\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, topicCount, id2word=dictionary, passes=30)\n",
    "    coherenceModelLda = CoherenceModel(model=ldamodel, texts=tokenized, dictionary=dictionary, coherence='c_v')\n",
    "    mockCoherenceModelLda = coherenceModelLda.get_coherence()\n",
    "    coherenceCountList.append(mockCoherenceModelLda)\n",
    "    topicCountList.append(topicCount)\n",
    "\n",
    "print(coherenceCountList)\n",
    "print(topicCountList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En iyi tutarlılık sonucunu veren topic sayısı grafiği\n",
    "plt.plot(topicCountList, coherenceCountList, '-')\n",
    "plt.xlabel('Topic Sayısı')\n",
    "plt.ylabel('Tutarlılık Skoru')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA Model Parametreleri\n",
    "df = pd.read_csv('assets/processed_comments/processed_comment.csv')\n",
    "tokenized = [comment.split() for comment in df[\"text\"].astype(str)]\n",
    "dictionary = corpora.Dictionary(tokenized)\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.7)\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in tokenized]\n",
    "\n",
    "#LDA Modelini Eğitme\n",
    "topicCount = 8 #Topic Sayısı\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, topicCount, id2word=dictionary, passes=30, alpha='auto', eta='auto')\n",
    "topics = ldamodel.print_topics(num_words=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA Modelinin Tutarlılık Skoru\n",
    "coherence_model_lda = CoherenceModel(model=ldamodel, texts=tokenized, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('LDA Tutarlılık Skoru: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA Topicleri\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA Topiclerini Dataframe Ekleme\n",
    "topicsDf = pd.DataFrame(topics, columns=['topic_id', 'top_words'])\n",
    "topicsDf.to_csv('results/lda/topicler.csv', index=False)\n",
    "topicsDf = pd.read_csv('results/lda/topicler.csv')\n",
    "topicsDf.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicDistsList = []\n",
    "documentTopicsList = []\n",
    "for i, docTopics in enumerate(ldamodel[corpus]):\n",
    "    dominantTopic = max(docTopics, key=lambda x: x[1])[0]\n",
    "    topicDistsList.append((df.iloc[i][\"text\"], dominantTopic))\n",
    "    documentTopics = ldamodel.get_document_topics(corpus[i])\n",
    "    documentTopicsList.append(documentTopics)\n",
    "    \n",
    "#Topiclerle yorumları eşleştirme\n",
    "topicDistsDf = pd.DataFrame(topicDistsList, columns=['document_text', 'topic_id'])\n",
    "topicDistsDf.to_csv('results/lda/yorumlarda_topic_dagilimlari.csv', index=False)\n",
    "\n",
    "#Topiciclerin yorumlardaki skoru\n",
    "documentTopicsDf = pd.DataFrame(documentTopicsList, columns=[f'topic_{i}' for i in range(ldamodel.num_topics)])\n",
    "documentTopicsDf.insert(0, 'document_id', range(1, len(documentTopicsDf) + 1))\n",
    "documentTopicsDf.to_csv('results/lda/topic_dagilimlari.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topiclerle yorumları eşleştirme dataframe\n",
    "topicDistsDf = pd.read_csv('results/lda/yorumlarda_topic_dagilimlari.csv')\n",
    "topicDistsDf.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topiciclerin yorumlardaki skoru dataframe\n",
    "documentTopicsDf = pd.read_csv('results/lda/topic_dagilimlari.csv')\n",
    "documentTopicsDf.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results/lda/topic_dagilimlari.csv')\n",
    "documentId = 28\n",
    "\n",
    "topicColumns = [col for col in df.columns if col.startswith('topic_')]\n",
    "topicCount = int(len(topicColumns))\n",
    "\n",
    "topicColumns = [f'topic_{i}' for i in range(topicCount-1)] \n",
    "topicIds = []\n",
    "topicScores = []\n",
    "\n",
    "for col in topicColumns:\n",
    "    topicInfo = df[df['document_id'] == documentId][col].values[0]\n",
    "    \n",
    "    if isinstance(topicInfo, float):\n",
    "        topicInfo = str(topicInfo)\n",
    "        \n",
    "    if ',' in topicInfo:\n",
    "        topicIdStr, scoreStr = topicInfo.split(\",\")\n",
    "        topicId = int(topicIdStr.strip(\"()\"))\n",
    "        score = float(scoreStr.strip(\")\"))\n",
    "        topicIds.append(topicId)\n",
    "        topicScores.append(score)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars = plt.bar(topicIds, topicScores, color='black', alpha=0.3)\n",
    "plt.title(f\"{documentId} idli Dökümanın Topic Skor Grafiği - LDA\")\n",
    "plt.xlabel(\"Topic ID\")\n",
    "plt.ylabel(\"Skor\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"results/lda/topicler.csv\")\n",
    "mostDominantTopicId = topicDistsDf['topic_id'].value_counts().idxmax()\n",
    "print(\"En fazla eşleşen topic: \", mostDominantTopicId)\n",
    "goal = data[data['topic_id'] == mostDominantTopicId][['top_words']]\n",
    "if not goal.empty:\n",
    "    print(\"Kelimeler: \", goal.iloc[0]['top_words'])\n",
    "else:\n",
    "    print(f\"{str(mostDominantTopicId)} idli topic bulunamadı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDf = pd.read_csv('results/lda/yorumlarda_topic_dagilimlari.csv')\n",
    "topicCount = resultsDf['topic_id'].nunique()\n",
    "topicDists = resultsDf['topic_id'].value_counts().sort_index()\n",
    "\n",
    "#Bar Grafiği\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(topicDists.index, topicDists.values, color='black', alpha=0.3)\n",
    "plt.title('Dökümanlardaki Topic Dağılımı - LDA')\n",
    "plt.xlabel('Topic ID')\n",
    "plt.xticks(ticks=range(0, topicCount), labels=range(0, topicCount))\n",
    "plt.ylabel('Döküman Sayısı')\n",
    "\n",
    "#Çubuk Grafiği\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(topicDists)), topicDists, marker='o', linestyle='-', color='black', label='Topic Dağılımı')\n",
    "plt.title('Dökümanlardaki Topic Dağılımı - LDA')\n",
    "plt.xlabel('Topic ID')\n",
    "plt.xticks(ticks=range(0, topicCount), labels=range(0, topicCount))\n",
    "plt.ylabel('Döküman Sayısı')\n",
    "plt.legend()\n",
    "\n",
    "#Pasta Grafiği\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "ax1.pie(topicDists.values, labels=topicDists.index, autopct='%1.1f%%', startangle=90, colors=plt.cm.tab10.colors)\n",
    "ax1.set_title('Dökümanlardaki Topic Dağılımı - LDA')\n",
    "\n",
    "ax2.text(0.1, 0.9, 'Topicler:', fontsize=8, weight='bold')\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "\n",
    "for i, topic_id in enumerate(topicDists.index):\n",
    "    ax2.text(0.1, 0.8 - i * 0.03, f'Topic {topic_id}, Eşleştiği Döküman Sayısı: {topicDists[topic_id]}', fontsize=8)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
